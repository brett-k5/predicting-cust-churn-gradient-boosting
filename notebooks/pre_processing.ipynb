{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Model to Predict When Customers Are Going to End Their Subscriptions For Interconnect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interconnect is a phone and internet provider who wants a machine learning model that can predict when customers are going to end their subscriptions ahead of time so that Interconnect can ensure their loyalty by offering them promotional offers. What follows is a data exploration and work plan for the best approach to accomplishing this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyarrow in c:\\users\\caitlin\\anaconda3\\envs\\sprint_17_env\\lib\\site-packages (21.0.0)\n",
      "Requirement already satisfied: shap in c:\\users\\caitlin\\anaconda3\\envs\\sprint_17_env\\lib\\site-packages (0.48.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\caitlin\\anaconda3\\envs\\sprint_17_env\\lib\\site-packages (from shap) (2.2.6)\n",
      "Requirement already satisfied: scipy in c:\\users\\caitlin\\anaconda3\\envs\\sprint_17_env\\lib\\site-packages (from shap) (1.16.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\caitlin\\anaconda3\\envs\\sprint_17_env\\lib\\site-packages (from shap) (1.7.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\caitlin\\anaconda3\\envs\\sprint_17_env\\lib\\site-packages (from shap) (2.3.2)\n",
      "Requirement already satisfied: tqdm>=4.27.0 in c:\\users\\caitlin\\anaconda3\\envs\\sprint_17_env\\lib\\site-packages (from shap) (4.67.1)\n",
      "Requirement already satisfied: packaging>20.9 in c:\\users\\caitlin\\anaconda3\\envs\\sprint_17_env\\lib\\site-packages (from shap) (25.0)\n",
      "Requirement already satisfied: slicer==0.0.8 in c:\\users\\caitlin\\anaconda3\\envs\\sprint_17_env\\lib\\site-packages (from shap) (0.0.8)\n",
      "Requirement already satisfied: numba>=0.54 in c:\\users\\caitlin\\anaconda3\\envs\\sprint_17_env\\lib\\site-packages (from shap) (0.61.2)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\caitlin\\anaconda3\\envs\\sprint_17_env\\lib\\site-packages (from shap) (3.1.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\caitlin\\anaconda3\\envs\\sprint_17_env\\lib\\site-packages (from shap) (4.14.1)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in c:\\users\\caitlin\\anaconda3\\envs\\sprint_17_env\\lib\\site-packages (from numba>=0.54->shap) (0.44.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\caitlin\\anaconda3\\envs\\sprint_17_env\\lib\\site-packages (from tqdm>=4.27.0->shap) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\caitlin\\anaconda3\\envs\\sprint_17_env\\lib\\site-packages (from pandas->shap) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\caitlin\\anaconda3\\envs\\sprint_17_env\\lib\\site-packages (from pandas->shap) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\caitlin\\anaconda3\\envs\\sprint_17_env\\lib\\site-packages (from pandas->shap) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\caitlin\\anaconda3\\envs\\sprint_17_env\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->shap) (1.17.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\caitlin\\anaconda3\\envs\\sprint_17_env\\lib\\site-packages (from scikit-learn->shap) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\caitlin\\anaconda3\\envs\\sprint_17_env\\lib\\site-packages (from scikit-learn->shap) (3.6.0)\n",
      "Requirement already satisfied: catboost in c:\\users\\caitlin\\anaconda3\\envs\\sprint_17_env\\lib\\site-packages (1.2.8)\n",
      "Requirement already satisfied: graphviz in c:\\users\\caitlin\\anaconda3\\envs\\sprint_17_env\\lib\\site-packages (from catboost) (0.21)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\caitlin\\anaconda3\\envs\\sprint_17_env\\lib\\site-packages (from catboost) (3.10.5)\n",
      "Requirement already satisfied: numpy<3.0,>=1.16.0 in c:\\users\\caitlin\\anaconda3\\envs\\sprint_17_env\\lib\\site-packages (from catboost) (2.2.6)\n",
      "Requirement already satisfied: pandas>=0.24 in c:\\users\\caitlin\\anaconda3\\envs\\sprint_17_env\\lib\\site-packages (from catboost) (2.3.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\caitlin\\anaconda3\\envs\\sprint_17_env\\lib\\site-packages (from catboost) (1.16.1)\n",
      "Requirement already satisfied: plotly in c:\\users\\caitlin\\anaconda3\\envs\\sprint_17_env\\lib\\site-packages (from catboost) (6.3.0)\n",
      "Requirement already satisfied: six in c:\\users\\caitlin\\anaconda3\\envs\\sprint_17_env\\lib\\site-packages (from catboost) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\caitlin\\anaconda3\\envs\\sprint_17_env\\lib\\site-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\caitlin\\anaconda3\\envs\\sprint_17_env\\lib\\site-packages (from pandas>=0.24->catboost) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\caitlin\\anaconda3\\envs\\sprint_17_env\\lib\\site-packages (from pandas>=0.24->catboost) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\caitlin\\anaconda3\\envs\\sprint_17_env\\lib\\site-packages (from matplotlib->catboost) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\caitlin\\anaconda3\\envs\\sprint_17_env\\lib\\site-packages (from matplotlib->catboost) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\caitlin\\anaconda3\\envs\\sprint_17_env\\lib\\site-packages (from matplotlib->catboost) (4.59.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\caitlin\\anaconda3\\envs\\sprint_17_env\\lib\\site-packages (from matplotlib->catboost) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\caitlin\\anaconda3\\envs\\sprint_17_env\\lib\\site-packages (from matplotlib->catboost) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\caitlin\\anaconda3\\envs\\sprint_17_env\\lib\\site-packages (from matplotlib->catboost) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\caitlin\\anaconda3\\envs\\sprint_17_env\\lib\\site-packages (from matplotlib->catboost) (3.2.3)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in c:\\users\\caitlin\\anaconda3\\envs\\sprint_17_env\\lib\\site-packages (from plotly->catboost) (2.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyarrow\n",
    "!pip install shap\n",
    "!pip install catboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Necessary Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Typing for type hints\n",
    "from typing import Optional\n",
    "\n",
    "# Standard library imports\n",
    "import re\n",
    "from functools import reduce\n",
    "import inspect\n",
    "\n",
    "# Third-party library imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Scikit-learn imports\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Caitlin\\Documents\\Brett_TTT_projects\\predicting_cust_churn\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_contract = pd.read_csv('contract.csv')\n",
    "df_personal = pd.read_csv('personal.csv')\n",
    "df_internet = pd.read_csv('internet.csv')\n",
    "df_phone = pd.read_csv('phone.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect Data and Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7043 entries, 0 to 7042\n",
      "Data columns (total 8 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   customerID        7043 non-null   object \n",
      " 1   BeginDate         7043 non-null   object \n",
      " 2   EndDate           7043 non-null   object \n",
      " 3   Type              7043 non-null   object \n",
      " 4   PaperlessBilling  7043 non-null   object \n",
      " 5   PaymentMethod     7043 non-null   object \n",
      " 6   MonthlyCharges    7043 non-null   float64\n",
      " 7   TotalCharges      7043 non-null   object \n",
      "dtypes: float64(1), object(7)\n",
      "memory usage: 440.3+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customerID</th>\n",
       "      <th>BeginDate</th>\n",
       "      <th>EndDate</th>\n",
       "      <th>Type</th>\n",
       "      <th>PaperlessBilling</th>\n",
       "      <th>PaymentMethod</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7590-VHVEG</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>29.85</td>\n",
       "      <td>29.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5575-GNVDE</td>\n",
       "      <td>2017-04-01</td>\n",
       "      <td>No</td>\n",
       "      <td>One year</td>\n",
       "      <td>No</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>56.95</td>\n",
       "      <td>1889.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3668-QPYBK</td>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>2019-12-01 00:00:00</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>53.85</td>\n",
       "      <td>108.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7795-CFOCW</td>\n",
       "      <td>2016-05-01</td>\n",
       "      <td>No</td>\n",
       "      <td>One year</td>\n",
       "      <td>No</td>\n",
       "      <td>Bank transfer (automatic)</td>\n",
       "      <td>42.30</td>\n",
       "      <td>1840.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9237-HQITU</td>\n",
       "      <td>2019-09-01</td>\n",
       "      <td>2019-11-01 00:00:00</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>70.70</td>\n",
       "      <td>151.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7038</th>\n",
       "      <td>6840-RESVB</td>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>No</td>\n",
       "      <td>One year</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>84.80</td>\n",
       "      <td>1990.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7039</th>\n",
       "      <td>2234-XADUH</td>\n",
       "      <td>2014-02-01</td>\n",
       "      <td>No</td>\n",
       "      <td>One year</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Credit card (automatic)</td>\n",
       "      <td>103.20</td>\n",
       "      <td>7362.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7040</th>\n",
       "      <td>4801-JZAZL</td>\n",
       "      <td>2019-03-01</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>29.60</td>\n",
       "      <td>346.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7041</th>\n",
       "      <td>8361-LTMKD</td>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>2019-11-01 00:00:00</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>74.40</td>\n",
       "      <td>306.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7042</th>\n",
       "      <td>3186-AJIEK</td>\n",
       "      <td>2014-08-01</td>\n",
       "      <td>No</td>\n",
       "      <td>Two year</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Bank transfer (automatic)</td>\n",
       "      <td>105.65</td>\n",
       "      <td>6844.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7043 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      customerID   BeginDate              EndDate            Type  \\\n",
       "0     7590-VHVEG  2020-01-01                   No  Month-to-month   \n",
       "1     5575-GNVDE  2017-04-01                   No        One year   \n",
       "2     3668-QPYBK  2019-10-01  2019-12-01 00:00:00  Month-to-month   \n",
       "3     7795-CFOCW  2016-05-01                   No        One year   \n",
       "4     9237-HQITU  2019-09-01  2019-11-01 00:00:00  Month-to-month   \n",
       "...          ...         ...                  ...             ...   \n",
       "7038  6840-RESVB  2018-02-01                   No        One year   \n",
       "7039  2234-XADUH  2014-02-01                   No        One year   \n",
       "7040  4801-JZAZL  2019-03-01                   No  Month-to-month   \n",
       "7041  8361-LTMKD  2019-07-01  2019-11-01 00:00:00  Month-to-month   \n",
       "7042  3186-AJIEK  2014-08-01                   No        Two year   \n",
       "\n",
       "     PaperlessBilling              PaymentMethod  MonthlyCharges TotalCharges  \n",
       "0                 Yes           Electronic check           29.85        29.85  \n",
       "1                  No               Mailed check           56.95       1889.5  \n",
       "2                 Yes               Mailed check           53.85       108.15  \n",
       "3                  No  Bank transfer (automatic)           42.30      1840.75  \n",
       "4                 Yes           Electronic check           70.70       151.65  \n",
       "...               ...                        ...             ...          ...  \n",
       "7038              Yes               Mailed check           84.80       1990.5  \n",
       "7039              Yes    Credit card (automatic)          103.20       7362.9  \n",
       "7040              Yes           Electronic check           29.60       346.45  \n",
       "7041              Yes               Mailed check           74.40        306.6  \n",
       "7042              Yes  Bank transfer (automatic)          105.65       6844.5  \n",
       "\n",
       "[7043 rows x 8 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_contract.info())\n",
    "df_contract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customerID          0\n",
       "BeginDate           0\n",
       "EndDate             0\n",
       "Type                0\n",
       "PaperlessBilling    0\n",
       "PaymentMethod       0\n",
       "MonthlyCharges      0\n",
       "TotalCharges        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_contract.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only column where a duplicate would indicate a surefire mistake would be 'customer_ID'. Let's give it a look. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_contract['customerID'].duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Date is another one we might not expect a duplicate. Let's checkt the unique value to see if we should expect duplicates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['No' '2019-12-01 00:00:00' '2019-11-01 00:00:00' '2019-10-01 00:00:00'\n",
      " '2020-01-01 00:00:00']\n"
     ]
    }
   ],
   "source": [
    "print(df_contract['EndDate'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, there is a pattern to when people end their subscriptions. All duplicates in this column are to be expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7043 entries, 0 to 7042\n",
      "Data columns (total 5 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   customerID     7043 non-null   object\n",
      " 1   gender         7043 non-null   object\n",
      " 2   SeniorCitizen  7043 non-null   int64 \n",
      " 3   Partner        7043 non-null   object\n",
      " 4   Dependents     7043 non-null   object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 275.2+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customerID</th>\n",
       "      <th>gender</th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>Partner</th>\n",
       "      <th>Dependents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7590-VHVEG</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5575-GNVDE</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3668-QPYBK</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7795-CFOCW</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9237-HQITU</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7038</th>\n",
       "      <td>6840-RESVB</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7039</th>\n",
       "      <td>2234-XADUH</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7040</th>\n",
       "      <td>4801-JZAZL</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7041</th>\n",
       "      <td>8361-LTMKD</td>\n",
       "      <td>Male</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7042</th>\n",
       "      <td>3186-AJIEK</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7043 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      customerID  gender  SeniorCitizen Partner Dependents\n",
       "0     7590-VHVEG  Female              0     Yes         No\n",
       "1     5575-GNVDE    Male              0      No         No\n",
       "2     3668-QPYBK    Male              0      No         No\n",
       "3     7795-CFOCW    Male              0      No         No\n",
       "4     9237-HQITU  Female              0      No         No\n",
       "...          ...     ...            ...     ...        ...\n",
       "7038  6840-RESVB    Male              0     Yes        Yes\n",
       "7039  2234-XADUH  Female              0     Yes        Yes\n",
       "7040  4801-JZAZL  Female              0     Yes        Yes\n",
       "7041  8361-LTMKD    Male              1     Yes         No\n",
       "7042  3186-AJIEK    Male              0      No         No\n",
       "\n",
       "[7043 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_personal.info())\n",
    "df_personal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customerID       0\n",
       "gender           0\n",
       "SeniorCitizen    0\n",
       "Partner          0\n",
       "Dependents       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_personal.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_personal.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_personal['customerID'].duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5517 entries, 0 to 5516\n",
      "Data columns (total 8 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   customerID        5517 non-null   object\n",
      " 1   InternetService   5517 non-null   object\n",
      " 2   OnlineSecurity    5517 non-null   object\n",
      " 3   OnlineBackup      5517 non-null   object\n",
      " 4   DeviceProtection  5517 non-null   object\n",
      " 5   TechSupport       5517 non-null   object\n",
      " 6   StreamingTV       5517 non-null   object\n",
      " 7   StreamingMovies   5517 non-null   object\n",
      "dtypes: object(8)\n",
      "memory usage: 344.9+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customerID</th>\n",
       "      <th>InternetService</th>\n",
       "      <th>OnlineSecurity</th>\n",
       "      <th>OnlineBackup</th>\n",
       "      <th>DeviceProtection</th>\n",
       "      <th>TechSupport</th>\n",
       "      <th>StreamingTV</th>\n",
       "      <th>StreamingMovies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7590-VHVEG</td>\n",
       "      <td>DSL</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5575-GNVDE</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3668-QPYBK</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7795-CFOCW</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9237-HQITU</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5512</th>\n",
       "      <td>6840-RESVB</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5513</th>\n",
       "      <td>2234-XADUH</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5514</th>\n",
       "      <td>4801-JZAZL</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5515</th>\n",
       "      <td>8361-LTMKD</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5516</th>\n",
       "      <td>3186-AJIEK</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5517 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      customerID InternetService OnlineSecurity OnlineBackup DeviceProtection  \\\n",
       "0     7590-VHVEG             DSL             No          Yes               No   \n",
       "1     5575-GNVDE             DSL            Yes           No              Yes   \n",
       "2     3668-QPYBK             DSL            Yes          Yes               No   \n",
       "3     7795-CFOCW             DSL            Yes           No              Yes   \n",
       "4     9237-HQITU     Fiber optic             No           No               No   \n",
       "...          ...             ...            ...          ...              ...   \n",
       "5512  6840-RESVB             DSL            Yes           No              Yes   \n",
       "5513  2234-XADUH     Fiber optic             No          Yes              Yes   \n",
       "5514  4801-JZAZL             DSL            Yes           No               No   \n",
       "5515  8361-LTMKD     Fiber optic             No           No               No   \n",
       "5516  3186-AJIEK     Fiber optic            Yes           No              Yes   \n",
       "\n",
       "     TechSupport StreamingTV StreamingMovies  \n",
       "0             No          No              No  \n",
       "1             No          No              No  \n",
       "2             No          No              No  \n",
       "3            Yes          No              No  \n",
       "4             No          No              No  \n",
       "...          ...         ...             ...  \n",
       "5512         Yes         Yes             Yes  \n",
       "5513          No         Yes             Yes  \n",
       "5514          No          No              No  \n",
       "5515          No          No              No  \n",
       "5516         Yes         Yes             Yes  \n",
       "\n",
       "[5517 rows x 8 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_internet.info())\n",
    "df_internet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customerID          0\n",
       "InternetService     0\n",
       "OnlineSecurity      0\n",
       "OnlineBackup        0\n",
       "DeviceProtection    0\n",
       "TechSupport         0\n",
       "StreamingTV         0\n",
       "StreamingMovies     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_internet.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_internet.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_internet['customerID'].duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6361 entries, 0 to 6360\n",
      "Data columns (total 2 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   customerID     6361 non-null   object\n",
      " 1   MultipleLines  6361 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 99.5+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customerID</th>\n",
       "      <th>MultipleLines</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5575-GNVDE</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3668-QPYBK</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9237-HQITU</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9305-CDSKC</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1452-KIOVK</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6356</th>\n",
       "      <td>2569-WGERO</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6357</th>\n",
       "      <td>6840-RESVB</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6358</th>\n",
       "      <td>2234-XADUH</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6359</th>\n",
       "      <td>8361-LTMKD</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6360</th>\n",
       "      <td>3186-AJIEK</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6361 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      customerID MultipleLines\n",
       "0     5575-GNVDE            No\n",
       "1     3668-QPYBK            No\n",
       "2     9237-HQITU            No\n",
       "3     9305-CDSKC           Yes\n",
       "4     1452-KIOVK           Yes\n",
       "...          ...           ...\n",
       "6356  2569-WGERO            No\n",
       "6357  6840-RESVB           Yes\n",
       "6358  2234-XADUH           Yes\n",
       "6359  8361-LTMKD           Yes\n",
       "6360  3186-AJIEK            No\n",
       "\n",
       "[6361 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_phone.info())\n",
    "df_phone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customerID       0\n",
       "MultipleLines    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_phone.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_phone['customerID'].duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of non-standard null values\n",
    "non_standard_null_values = ['', 'na', 'null', 'missing']\n",
    "\n",
    "def non_standard_null_search(df):\n",
    "    for col in df.columns:\n",
    "        # Create conditional \"if the datatype for a given column is object datatype.\" \n",
    "        if df[col].dtype == 'object': \n",
    "            # Assign each column the value it previusly had except with all lower case and all trailing \n",
    "            # and leadings spaces stripped. \n",
    "            df[col] = df[col].str.strip().str.lower()\n",
    "            # For each column display the non-standard null values it contains. \n",
    "            print(f\"{col}: {df[col].isin(non_standard_null_values).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "customerID: 0\n",
      "BeginDate: 0\n",
      "EndDate: 0\n",
      "Type: 0\n",
      "PaperlessBilling: 0\n",
      "PaymentMethod: 0\n",
      "TotalCharges: 11\n"
     ]
    }
   ],
   "source": [
    "non_standard_null_search(df_contract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customerID</th>\n",
       "      <th>BeginDate</th>\n",
       "      <th>EndDate</th>\n",
       "      <th>Type</th>\n",
       "      <th>PaperlessBilling</th>\n",
       "      <th>PaymentMethod</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7590-vhveg</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>no</td>\n",
       "      <td>month-to-month</td>\n",
       "      <td>yes</td>\n",
       "      <td>electronic check</td>\n",
       "      <td>29.85</td>\n",
       "      <td>29.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5575-gnvde</td>\n",
       "      <td>2017-04-01</td>\n",
       "      <td>no</td>\n",
       "      <td>one year</td>\n",
       "      <td>no</td>\n",
       "      <td>mailed check</td>\n",
       "      <td>56.95</td>\n",
       "      <td>1889.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3668-qpybk</td>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>2019-12-01 00:00:00</td>\n",
       "      <td>month-to-month</td>\n",
       "      <td>yes</td>\n",
       "      <td>mailed check</td>\n",
       "      <td>53.85</td>\n",
       "      <td>108.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7795-cfocw</td>\n",
       "      <td>2016-05-01</td>\n",
       "      <td>no</td>\n",
       "      <td>one year</td>\n",
       "      <td>no</td>\n",
       "      <td>bank transfer (automatic)</td>\n",
       "      <td>42.30</td>\n",
       "      <td>1840.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9237-hqitu</td>\n",
       "      <td>2019-09-01</td>\n",
       "      <td>2019-11-01 00:00:00</td>\n",
       "      <td>month-to-month</td>\n",
       "      <td>yes</td>\n",
       "      <td>electronic check</td>\n",
       "      <td>70.70</td>\n",
       "      <td>151.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customerID   BeginDate              EndDate            Type  \\\n",
       "0  7590-vhveg  2020-01-01                   no  month-to-month   \n",
       "1  5575-gnvde  2017-04-01                   no        one year   \n",
       "2  3668-qpybk  2019-10-01  2019-12-01 00:00:00  month-to-month   \n",
       "3  7795-cfocw  2016-05-01                   no        one year   \n",
       "4  9237-hqitu  2019-09-01  2019-11-01 00:00:00  month-to-month   \n",
       "\n",
       "  PaperlessBilling              PaymentMethod  MonthlyCharges TotalCharges  \n",
       "0              yes           electronic check           29.85        29.85  \n",
       "1               no               mailed check           56.95       1889.5  \n",
       "2              yes               mailed check           53.85       108.15  \n",
       "3               no  bank transfer (automatic)           42.30      1840.75  \n",
       "4              yes           electronic check           70.70       151.65  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_contract.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['29.85', '1889.5', '108.15', ..., '346.45', '306.6', '6844.5'],\n",
       "      shape=(6531,), dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_contract['TotalCharges'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "488     \n",
      "753     \n",
      "936     \n",
      "1082    \n",
      "1340    \n",
      "3331    \n",
      "3826    \n",
      "4380    \n",
      "5218    \n",
      "6670    \n",
      "6754    \n",
      "Name: TotalCharges, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Caitlin\\AppData\\Local\\Temp\\ipykernel_29516\\1235251770.py:1: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  mask = df_contract['TotalCharges'].astype(str).str.contains('([a-zA-Z]+|^$)', na=False)\n"
     ]
    }
   ],
   "source": [
    "mask = df_contract['TotalCharges'].astype(str).str.contains('([a-zA-Z]+|^$)', na=False)\n",
    "print(df_contract.loc[mask, 'TotalCharges'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, we are dealing with some empty strings in the total_charges column. Since we are going to rely on gradient boosting algorithms for this project we can use to_numeric and coerce the empty strings to NaN values because gradient boosting algorithms can handle NaN values gracefully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numeric and coerce errors to NaN\n",
    "df_contract['TotalCharges'] = pd.to_numeric(df_contract['TotalCharges'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "customerID: 0\n",
      "gender: 0\n",
      "Partner: 0\n",
      "Dependents: 0\n"
     ]
    }
   ],
   "source": [
    "non_standard_null_search(df_personal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "customerID: 0\n",
      "InternetService: 0\n",
      "OnlineSecurity: 0\n",
      "OnlineBackup: 0\n",
      "DeviceProtection: 0\n",
      "TechSupport: 0\n",
      "StreamingTV: 0\n",
      "StreamingMovies: 0\n"
     ]
    }
   ],
   "source": [
    "non_standard_null_search(df_internet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "customerID: 0\n",
      "MultipleLines: 0\n"
     ]
    }
   ],
   "source": [
    "non_standard_null_search(df_phone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customerID</th>\n",
       "      <th>MultipleLines</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5575-gnvde</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3668-qpybk</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9237-hqitu</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9305-cdskc</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1452-kiovk</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customerID MultipleLines\n",
       "0  5575-gnvde            no\n",
       "1  3668-qpybk            no\n",
       "2  9237-hqitu            no\n",
       "3  9305-cdskc           yes\n",
       "4  1452-kiovk           yes"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_phone.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_column_names(name):\n",
    "    name = name.strip()\n",
    "    # Insert underscore before a capital letter preceded by a lowercase letter or number \n",
    "    return re.sub(r'(?<=[a-z0-9])([A-Z])', r'_\\1', name).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['customer_id', 'begin_date', 'end_date', 'type', 'paperless_billing',\n",
       "       'payment_method', 'monthly_charges', 'total_charges'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_contract.columns = [clean_column_names(col) for col in df_contract.columns]\n",
    "df_contract.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['customer_id', 'gender', 'senior_citizen', 'partner', 'dependents'], dtype='object')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_personal.columns = [clean_column_names(col) for col in df_personal.columns]\n",
    "df_personal.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['customer_id', 'internet_service', 'online_security', 'online_backup',\n",
       "       'device_protection', 'tech_support', 'streaming_tv',\n",
       "       'streaming_movies'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_internet.columns = [clean_column_names(col) for col in df_internet.columns]\n",
    "df_internet.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['customer_id', 'multiple_lines'], dtype='object')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_phone.columns = [clean_column_names(col) for col in df_phone.columns]\n",
    "df_phone.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_contract['begin_date'] = pd.to_datetime(df_contract['begin_date'], format=\"%Y-%m-%d\", errors='coerce')\n",
    "df_contract['end_date'] = pd.to_datetime(df_contract['end_date'].replace(\"No\", pd.NaT), format=\"%Y-%m-%d %H:%M:%S\", errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DatetimeArray>\n",
       "[                'NaT', '2019-12-01 00:00:00', '2019-11-01 00:00:00',\n",
       " '2019-10-01 00:00:00', '2020-01-01 00:00:00']\n",
       "Length: 5, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_contract['end_date'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work Plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have four DataFrames: df_contract, df_personal, df_internet, and df_phone. Ultimately, we want to be able to feed our model as much information as possible. Hower, there is a problem, because not every customer who has phone service also has internet service and vice versa. This means that if we use all of the features we will have large number of NaN values in phone categories for customers who only have internet and vice versa. For this reason (and others) gradient boosting algorithms are ideal for this task. They can handle the NaN values natively, which means that we can simply merge these DataFrames without worrying about the NaN values that are created. \n",
    "\n",
    "There are a lot of creative feature engineering approaches we can take as well. One thing we can do is set up a p_i_or_b feature (phone, internet, or both). There are also a lot of options available to us utilizing the date features from df_contract: begin_date and end_date. Of course, end_date will ultimately be converted into our binary target_feature 'churn'. Therefore, we cannot directly utilize information from end_date because it would be giving away the answers to the model. However, we can use it to create a 'customer_duration' feature, which could be a real asset. We can also extract a number of features from begin date. We can get the year, the month, the day of the year, the day of the month, and the day of the weak. Moreover, we can encode these both as categorical variables, and as intervals on the unit circle (via sin and cosine) which would of course be numeric variables. To the degree that the categorical nature of the variable is what is predictive the model can rely on the extracted date features which are encoded as categorical variables. To the extent that cyclical trends are predictive (i.e. later in the week as opposed to Friday specifically) the model can rely on the numeric versions of the extracted date features. \n",
    "\n",
    "Unfortunately, the model cannot utilize both the extracted date features and a customer_duration feature, as knowledge of the start date in conjunction with the subscription duration would lead to data leakage. For example, if the customer signed up in 2014, but the duration is under 300 days, the model will automatically know the customer churned. There may be an exception for dayofweek features, but this is tricky too. Since all contracts start and end on the first of the month. This would mean that if two customers started on different days but had the same duration, assuming they have the same contract type, one of them would have had to have churned. So, again, we would be dealing with a data leakage problem. Another concern regarding a 'customer_duration' feature is that, in real life, if the model requires a duration metric up to the present date to make a prediction, it is useless, because the promotional offer likely will not make it onto the customer's radard before they decide to churn. Instead we want to be able to predict churn at least a week or two in advance. \n",
    "\n",
    "We can, potentially kill two birds with one stone by subtracting random values from customer duration. We would want a values that are roughly equal to the time by which we want to pre-empt a predicted churn with a promotional offer. We would also want a range of values large enough to erase any delimiting capabilities that could be available to dayofweek_sin and dayofweek_cos. Since the farthest two days in a week can be from each other (when cyclicality is taken into account) is 3 on either the front end or the back end, a range of 3 would be a good place to start. With all these considerations in mind I will use random float values between 12 and 15 for this purpose if we decide it is adventageous to implement it. By subtracting these days we have also created a model that can predict the churn ahead of time so it will be ready for real world implementation. \n",
    "\n",
    "Once we have our different feature options we will try the different combinations of features that do not lead to data leakage with LightGBM, CatBoost, and XGBoost classififiers. The models themselves will have their hyperparameters tuned via GridSearchCV in a GPU envrionment on google colab (utilizing A100 GPUs). \n",
    "\n",
    "So with all of that in mind, here are the steps that have to be taken from here on out to complete the project:\n",
    "\n",
    "1. Merge DataFrames\n",
    "2. Eingeer all aforementinoed features\n",
    "3. Perform EDA - specifically, make sure training distributions match test distributions\n",
    "4. Make necessary adjustements to data for the given model (LGBM and XGB handle categorical variables differently than CatBoost)\n",
    "5. Check which non-data leakage inducing combination of features the model performs best with via GridSearch cross validation\n",
    "6. Adjust features based on SHAP output\n",
    "8. Tune hyperparameters for models with best fetures\n",
    "9. Retrain model on full training set and test model\n",
    "\n",
    "Steps 1 and 2 will be completed in what remains of this notebook. 3 will be completed in a separate EDA notebook, and the rest will be completed via .py scripts which are will be generated at the end of this notebook. \n",
    "\n",
    "The questions which we have yet to answer are as follows:\n",
    "\n",
    "1. Can we utilize the 'customer_duration' feature without introducing data leakage? \n",
    "2. Can we utilize 'customer_duration' with start_dayofweek_sin, start_dayofweek_cos, and start_dayofweek_cat without introducing data leakage?\n",
    "3. What non data leakage inducing combinatino of features will lead to the best model performance? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ultimately, we will merge all of the DataFrames in one line of code. However, merging df_personal and df_contract will help us engineer our 'p_i_or_b' feature. So, that is where we will start. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge df_personal and df_contract\n",
    "personal_and_contract = pd.merge(df_contract, df_personal, on='customer_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7043 entries, 0 to 7042\n",
      "Data columns (total 12 columns):\n",
      " #   Column             Non-Null Count  Dtype         \n",
      "---  ------             --------------  -----         \n",
      " 0   customer_id        7043 non-null   object        \n",
      " 1   begin_date         7043 non-null   datetime64[ns]\n",
      " 2   end_date           1869 non-null   datetime64[ns]\n",
      " 3   type               7043 non-null   object        \n",
      " 4   paperless_billing  7043 non-null   object        \n",
      " 5   payment_method     7043 non-null   object        \n",
      " 6   monthly_charges    7043 non-null   float64       \n",
      " 7   total_charges      7032 non-null   float64       \n",
      " 8   gender             7043 non-null   object        \n",
      " 9   senior_citizen     7043 non-null   int64         \n",
      " 10  partner            7043 non-null   object        \n",
      " 11  dependents         7043 non-null   object        \n",
      "dtypes: datetime64[ns](2), float64(2), int64(1), object(7)\n",
      "memory usage: 660.4+ KB\n"
     ]
    }
   ],
   "source": [
    "personal_and_contract.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all loaded DataFrames (still for the sake of feature engineering)\n",
    "dfs = [df_contract, df_personal, df_internet, df_phone]\n",
    "merged_df = reduce(lambda left, right: pd.merge(left, right, on='customer_id', how='inner'), dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4835 entries, 0 to 4834\n",
      "Data columns (total 20 columns):\n",
      " #   Column             Non-Null Count  Dtype         \n",
      "---  ------             --------------  -----         \n",
      " 0   customer_id        4835 non-null   object        \n",
      " 1   begin_date         4835 non-null   datetime64[ns]\n",
      " 2   end_date           1586 non-null   datetime64[ns]\n",
      " 3   type               4835 non-null   object        \n",
      " 4   paperless_billing  4835 non-null   object        \n",
      " 5   payment_method     4835 non-null   object        \n",
      " 6   monthly_charges    4835 non-null   float64       \n",
      " 7   total_charges      4832 non-null   float64       \n",
      " 8   gender             4835 non-null   object        \n",
      " 9   senior_citizen     4835 non-null   int64         \n",
      " 10  partner            4835 non-null   object        \n",
      " 11  dependents         4835 non-null   object        \n",
      " 12  internet_service   4835 non-null   object        \n",
      " 13  online_security    4835 non-null   object        \n",
      " 14  online_backup      4835 non-null   object        \n",
      " 15  device_protection  4835 non-null   object        \n",
      " 16  tech_support       4835 non-null   object        \n",
      " 17  streaming_tv       4835 non-null   object        \n",
      " 18  streaming_movies   4835 non-null   object        \n",
      " 19  multiple_lines     4835 non-null   object        \n",
      "dtypes: datetime64[ns](2), float64(2), int64(1), object(15)\n",
      "memory usage: 755.6+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(merged_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We performed an inner merge for df_personal and df_contract, and we also performed an inner merge between those two DataFrames and the remaning DataFrames we have loaded as well. The reason for this is that we wanted to create boolean masks using the presence of 'customer_id' in these respective DataFrames. We will have a mask for when customer_id appears in both phone and internet, one for when it appears in df_phone only, and another for when it appears in df_internet only. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "personal_and_contract['p_i_or_b'] = None # initialize column\n",
    "\n",
    "# Create boolean masks that return True when conditions our met\n",
    "mask_both = personal_and_contract['customer_id'].isin(merged_df['customer_id'])\n",
    "mask_internet = personal_and_contract['customer_id'].isin(df_internet['customer_id'])\n",
    "mask_phone = personal_and_contract['customer_id'].isin(df_phone['customer_id'])\n",
    "\n",
    "# Use boolean masks with .loc to engineer 'p-i_or_b' feature\n",
    "personal_and_contract.loc[mask_both, 'p_i_or_b'] = 'both'\n",
    "personal_and_contract.loc[~mask_both & mask_internet, 'p_i_or_b'] = 'internet'\n",
    "personal_and_contract.loc[~mask_both & ~mask_internet & mask_phone, 'p_i_or_b'] = 'phone'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7043 entries, 0 to 7042\n",
      "Data columns (total 13 columns):\n",
      " #   Column             Non-Null Count  Dtype         \n",
      "---  ------             --------------  -----         \n",
      " 0   customer_id        7043 non-null   object        \n",
      " 1   begin_date         7043 non-null   datetime64[ns]\n",
      " 2   end_date           1869 non-null   datetime64[ns]\n",
      " 3   type               7043 non-null   object        \n",
      " 4   paperless_billing  7043 non-null   object        \n",
      " 5   payment_method     7043 non-null   object        \n",
      " 6   monthly_charges    7043 non-null   float64       \n",
      " 7   total_charges      7032 non-null   float64       \n",
      " 8   gender             7043 non-null   object        \n",
      " 9   senior_citizen     7043 non-null   int64         \n",
      " 10  partner            7043 non-null   object        \n",
      " 11  dependents         7043 non-null   object        \n",
      " 12  p_i_or_b           7043 non-null   object        \n",
      "dtypes: datetime64[ns](2), float64(2), int64(1), object(8)\n",
      "memory usage: 715.4+ KB\n"
     ]
    }
   ],
   "source": [
    "personal_and_contract.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [personal_and_contract, df_internet, df_phone]\n",
    "\n",
    "# We are going to perform an outer merge because we don't want to lose data and the resulting NaN values will not be a problem \n",
    "# for the gradient boosting models we will train.\n",
    "all_data = reduce(lambda left, right: pd.merge(left, right, on='customer_id', how='outer'), dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7043 entries, 0 to 7042\n",
      "Data columns (total 21 columns):\n",
      " #   Column             Non-Null Count  Dtype         \n",
      "---  ------             --------------  -----         \n",
      " 0   customer_id        7043 non-null   object        \n",
      " 1   begin_date         7043 non-null   datetime64[ns]\n",
      " 2   end_date           1869 non-null   datetime64[ns]\n",
      " 3   type               7043 non-null   object        \n",
      " 4   paperless_billing  7043 non-null   object        \n",
      " 5   payment_method     7043 non-null   object        \n",
      " 6   monthly_charges    7043 non-null   float64       \n",
      " 7   total_charges      7032 non-null   float64       \n",
      " 8   gender             7043 non-null   object        \n",
      " 9   senior_citizen     7043 non-null   int64         \n",
      " 10  partner            7043 non-null   object        \n",
      " 11  dependents         7043 non-null   object        \n",
      " 12  p_i_or_b           7043 non-null   object        \n",
      " 13  internet_service   5517 non-null   object        \n",
      " 14  online_security    5517 non-null   object        \n",
      " 15  online_backup      5517 non-null   object        \n",
      " 16  device_protection  5517 non-null   object        \n",
      " 17  tech_support       5517 non-null   object        \n",
      " 18  streaming_tv       5517 non-null   object        \n",
      " 19  streaming_movies   5517 non-null   object        \n",
      " 20  multiple_lines     6361 non-null   object        \n",
      "dtypes: datetime64[ns](2), float64(2), int64(1), object(16)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "all_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>begin_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>type</th>\n",
       "      <th>paperless_billing</th>\n",
       "      <th>payment_method</th>\n",
       "      <th>monthly_charges</th>\n",
       "      <th>total_charges</th>\n",
       "      <th>gender</th>\n",
       "      <th>senior_citizen</th>\n",
       "      <th>...</th>\n",
       "      <th>p_i_or_b</th>\n",
       "      <th>internet_service</th>\n",
       "      <th>online_security</th>\n",
       "      <th>online_backup</th>\n",
       "      <th>device_protection</th>\n",
       "      <th>tech_support</th>\n",
       "      <th>streaming_tv</th>\n",
       "      <th>streaming_movies</th>\n",
       "      <th>multiple_lines</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0002-orfbo</td>\n",
       "      <td>2019-05-01</td>\n",
       "      <td>NaT</td>\n",
       "      <td>one year</td>\n",
       "      <td>yes</td>\n",
       "      <td>mailed check</td>\n",
       "      <td>65.6</td>\n",
       "      <td>593.30</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>both</td>\n",
       "      <td>dsl</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0003-mknfe</td>\n",
       "      <td>2019-05-01</td>\n",
       "      <td>NaT</td>\n",
       "      <td>month-to-month</td>\n",
       "      <td>no</td>\n",
       "      <td>mailed check</td>\n",
       "      <td>59.9</td>\n",
       "      <td>542.40</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>both</td>\n",
       "      <td>dsl</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0004-tlhlj</td>\n",
       "      <td>2019-09-01</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>month-to-month</td>\n",
       "      <td>yes</td>\n",
       "      <td>electronic check</td>\n",
       "      <td>73.9</td>\n",
       "      <td>280.85</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>both</td>\n",
       "      <td>fiber optic</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0011-igkff</td>\n",
       "      <td>2018-12-01</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>month-to-month</td>\n",
       "      <td>yes</td>\n",
       "      <td>electronic check</td>\n",
       "      <td>98.0</td>\n",
       "      <td>1237.85</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>both</td>\n",
       "      <td>fiber optic</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0013-exchz</td>\n",
       "      <td>2019-09-01</td>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>month-to-month</td>\n",
       "      <td>yes</td>\n",
       "      <td>mailed check</td>\n",
       "      <td>83.9</td>\n",
       "      <td>267.40</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>both</td>\n",
       "      <td>fiber optic</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  customer_id begin_date   end_date            type paperless_billing  \\\n",
       "0  0002-orfbo 2019-05-01        NaT        one year               yes   \n",
       "1  0003-mknfe 2019-05-01        NaT  month-to-month                no   \n",
       "2  0004-tlhlj 2019-09-01 2020-01-01  month-to-month               yes   \n",
       "3  0011-igkff 2018-12-01 2020-01-01  month-to-month               yes   \n",
       "4  0013-exchz 2019-09-01 2019-12-01  month-to-month               yes   \n",
       "\n",
       "     payment_method  monthly_charges  total_charges  gender  senior_citizen  \\\n",
       "0      mailed check             65.6         593.30  female               0   \n",
       "1      mailed check             59.9         542.40    male               0   \n",
       "2  electronic check             73.9         280.85    male               0   \n",
       "3  electronic check             98.0        1237.85    male               1   \n",
       "4      mailed check             83.9         267.40  female               1   \n",
       "\n",
       "   ... p_i_or_b internet_service online_security online_backup  \\\n",
       "0  ...     both              dsl              no           yes   \n",
       "1  ...     both              dsl              no            no   \n",
       "2  ...     both      fiber optic              no            no   \n",
       "3  ...     both      fiber optic              no           yes   \n",
       "4  ...     both      fiber optic              no            no   \n",
       "\n",
       "  device_protection tech_support streaming_tv streaming_movies multiple_lines  \\\n",
       "0                no          yes          yes               no             no   \n",
       "1                no           no           no              yes            yes   \n",
       "2               yes           no           no               no             no   \n",
       "3               yes           no          yes              yes             no   \n",
       "4                no          yes          yes               no             no   \n",
       "\n",
       "  churn  \n",
       "0     0  \n",
       "1     0  \n",
       "2     1  \n",
       "3     1  \n",
       "4     1  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a target column from 'end_date' column \n",
    "all_data['churn'] = np.where(all_data['end_date'].isna(), 0, 1)\n",
    "all_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a date to use to create our 'customer_duration' feature. We will use the latest date available in any of our data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-02-01 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Find the most recent date across both date columns\n",
    "latest_date = pd.concat([all_data['begin_date'], all_data['end_date']]).max()\n",
    "print(latest_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As noted in the data description we were provided, the most recent date in the data set is February 1, 2020. For the sake of engineering a 'customer_duration' feature, we will assume that we are creating this model on February 1, 2020. Therefore, any accounts that are still active will only be considered to be active as of February 1, 2020 as opposed to today's actual date. However, we will be subtracting a random float value between 13 and 15 from the initial 'customer_duration' feature. This means that the models will be trained on data we would have available to us at the time we want to make our predictions in the real world. It will also prevent any data leakage that might result from regular patterns that appear between 'customer_duration' and 'churn'. If certain durations are always churned and others are never churned, we are certainly comitting the sin of data leakage. By subtracting random values between 13 and 15 we can introduce a little randomness into our 'customer_duration' feature. This is especially important if we want to maintain any day_of_week features in our training data. Moreover, because we are keeping the range of values we are subtracting to 3 days we will not negatively impact any signal that exists between 'customer_duration' and 'churn'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate customer duration\n",
    "all_data['customer_duration'] = np.where(\n",
    "    all_data['end_date'].isna(), (latest_date - all_data['begin_date']).dt.days, (\n",
    "        all_data['end_date'] - all_data['begin_date']).dt.days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2020-02-01 00:00:00')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data['begin_date'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data['customer_duration'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's subtract random float values between 12 and 15."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.999717816257826\n",
      "12.00014463425858\n"
     ]
    }
   ],
   "source": [
    "# Generate a different random value between 13 and 15 for each row\n",
    "random_values = np.random.uniform(12, 15, size=len(all_data))\n",
    "\n",
    "#Check to make sure our random values are what we expect them to be\n",
    "print(random_values.max())\n",
    "print(random_values.min())\n",
    "\n",
    "# Subtract random float values from 'customer_duration\n",
    "all_data['customer_duration'] = all_data['customer_duration'] - random_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Engineering date features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's engineer our other date features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['start_year_int'] = all_data['begin_date'].dt.year.astype(int)\n",
    "\n",
    "all_data['start_year_cat'] = all_data['begin_date'].dt.year.astype(str)\n",
    "\n",
    "all_data['start_month_int'] = all_data['begin_date'].dt.month.astype(int)\n",
    "\n",
    "all_data['start_month_cat'] = all_data['begin_date'].dt.day.astype(str)\n",
    "\n",
    "all_data['start_dayofmonth_int'] = all_data['begin_date'].dt.day.astype(int)\n",
    "\n",
    "all_data['start_dayofmonth_cat'] = all_data['begin_date'].dt.day.astype(str)\n",
    "\n",
    "all_data['start_dayofweek_int'] = all_data['begin_date'].dt.dayofweek.astype(int) + 1\n",
    "\n",
    "all_data['start_dayofweek_cat'] = all_data['begin_date'].dt.dayofweek.astype(str)\n",
    "\n",
    "all_data['start_dayofyear_int'] = all_data['begin_date'].dt.dayofyear.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>begin_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>type</th>\n",
       "      <th>paperless_billing</th>\n",
       "      <th>payment_method</th>\n",
       "      <th>monthly_charges</th>\n",
       "      <th>total_charges</th>\n",
       "      <th>gender</th>\n",
       "      <th>senior_citizen</th>\n",
       "      <th>...</th>\n",
       "      <th>customer_duration</th>\n",
       "      <th>start_year_int</th>\n",
       "      <th>start_year_cat</th>\n",
       "      <th>start_month_int</th>\n",
       "      <th>start_month_cat</th>\n",
       "      <th>start_dayofmonth_int</th>\n",
       "      <th>start_dayofmonth_cat</th>\n",
       "      <th>start_dayofweek_int</th>\n",
       "      <th>start_dayofweek_cat</th>\n",
       "      <th>start_dayofyear_int</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0002-orfbo</td>\n",
       "      <td>2019-05-01</td>\n",
       "      <td>NaT</td>\n",
       "      <td>one year</td>\n",
       "      <td>yes</td>\n",
       "      <td>mailed check</td>\n",
       "      <td>65.6</td>\n",
       "      <td>593.30</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>261.086707</td>\n",
       "      <td>2019</td>\n",
       "      <td>2019</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0003-mknfe</td>\n",
       "      <td>2019-05-01</td>\n",
       "      <td>NaT</td>\n",
       "      <td>month-to-month</td>\n",
       "      <td>no</td>\n",
       "      <td>mailed check</td>\n",
       "      <td>59.9</td>\n",
       "      <td>542.40</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>261.113430</td>\n",
       "      <td>2019</td>\n",
       "      <td>2019</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0004-tlhlj</td>\n",
       "      <td>2019-09-01</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>month-to-month</td>\n",
       "      <td>yes</td>\n",
       "      <td>electronic check</td>\n",
       "      <td>73.9</td>\n",
       "      <td>280.85</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>108.220991</td>\n",
       "      <td>2019</td>\n",
       "      <td>2019</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0011-igkff</td>\n",
       "      <td>2018-12-01</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>month-to-month</td>\n",
       "      <td>yes</td>\n",
       "      <td>electronic check</td>\n",
       "      <td>98.0</td>\n",
       "      <td>1237.85</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>382.821665</td>\n",
       "      <td>2018</td>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0013-exchz</td>\n",
       "      <td>2019-09-01</td>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>month-to-month</td>\n",
       "      <td>yes</td>\n",
       "      <td>mailed check</td>\n",
       "      <td>83.9</td>\n",
       "      <td>267.40</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>76.251027</td>\n",
       "      <td>2019</td>\n",
       "      <td>2019</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>244</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  customer_id begin_date   end_date            type paperless_billing  \\\n",
       "0  0002-orfbo 2019-05-01        NaT        one year               yes   \n",
       "1  0003-mknfe 2019-05-01        NaT  month-to-month                no   \n",
       "2  0004-tlhlj 2019-09-01 2020-01-01  month-to-month               yes   \n",
       "3  0011-igkff 2018-12-01 2020-01-01  month-to-month               yes   \n",
       "4  0013-exchz 2019-09-01 2019-12-01  month-to-month               yes   \n",
       "\n",
       "     payment_method  monthly_charges  total_charges  gender  senior_citizen  \\\n",
       "0      mailed check             65.6         593.30  female               0   \n",
       "1      mailed check             59.9         542.40    male               0   \n",
       "2  electronic check             73.9         280.85    male               0   \n",
       "3  electronic check             98.0        1237.85    male               1   \n",
       "4      mailed check             83.9         267.40  female               1   \n",
       "\n",
       "   ... customer_duration start_year_int start_year_cat start_month_int  \\\n",
       "0  ...        261.086707           2019           2019               5   \n",
       "1  ...        261.113430           2019           2019               5   \n",
       "2  ...        108.220991           2019           2019               9   \n",
       "3  ...        382.821665           2018           2018              12   \n",
       "4  ...         76.251027           2019           2019               9   \n",
       "\n",
       "  start_month_cat start_dayofmonth_int start_dayofmonth_cat  \\\n",
       "0               1                    1                    1   \n",
       "1               1                    1                    1   \n",
       "2               1                    1                    1   \n",
       "3               1                    1                    1   \n",
       "4               1                    1                    1   \n",
       "\n",
       "  start_dayofweek_int start_dayofweek_cat start_dayofyear_int  \n",
       "0                   3                   2                 121  \n",
       "1                   3                   2                 121  \n",
       "2                   7                   6                 244  \n",
       "3                   6                   5                 335  \n",
       "4                   7                   6                 244  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create function that adds sin and cos columns to capture cyclical patterns for a given column.\n",
    "def add_cyclical_features(df: pd.DataFrame, old_col_name: str, new_col_name:str, max_val: float) -> pd.DataFrame:\n",
    "    df[new_col_name + '_sin'] = np.sin(2 * np.pi * df[old_col_name] / max_val)\n",
    "    df[new_col_name + '_cos'] = np.cos(2 * np.pi * df[old_col_name] / max_val)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7043 entries, 0 to 7042\n",
      "Data columns (total 32 columns):\n",
      " #   Column                Non-Null Count  Dtype         \n",
      "---  ------                --------------  -----         \n",
      " 0   customer_id           7043 non-null   object        \n",
      " 1   begin_date            7043 non-null   datetime64[ns]\n",
      " 2   end_date              1869 non-null   datetime64[ns]\n",
      " 3   type                  7043 non-null   object        \n",
      " 4   paperless_billing     7043 non-null   object        \n",
      " 5   payment_method        7043 non-null   object        \n",
      " 6   monthly_charges       7043 non-null   float64       \n",
      " 7   total_charges         7032 non-null   float64       \n",
      " 8   gender                7043 non-null   object        \n",
      " 9   senior_citizen        7043 non-null   int64         \n",
      " 10  partner               7043 non-null   object        \n",
      " 11  dependents            7043 non-null   object        \n",
      " 12  p_i_or_b              7043 non-null   object        \n",
      " 13  internet_service      5517 non-null   object        \n",
      " 14  online_security       5517 non-null   object        \n",
      " 15  online_backup         5517 non-null   object        \n",
      " 16  device_protection     5517 non-null   object        \n",
      " 17  tech_support          5517 non-null   object        \n",
      " 18  streaming_tv          5517 non-null   object        \n",
      " 19  streaming_movies      5517 non-null   object        \n",
      " 20  multiple_lines        6361 non-null   object        \n",
      " 21  churn                 7043 non-null   int64         \n",
      " 22  customer_duration     7043 non-null   float64       \n",
      " 23  start_year_int        7043 non-null   int64         \n",
      " 24  start_year_cat        7043 non-null   object        \n",
      " 25  start_month_int       7043 non-null   int64         \n",
      " 26  start_month_cat       7043 non-null   object        \n",
      " 27  start_dayofmonth_int  7043 non-null   int64         \n",
      " 28  start_dayofmonth_cat  7043 non-null   object        \n",
      " 29  start_dayofweek_int   7043 non-null   int64         \n",
      " 30  start_dayofweek_cat   7043 non-null   object        \n",
      " 31  start_dayofyear_int   7043 non-null   int64         \n",
      "dtypes: datetime64[ns](2), float64(3), int64(7), object(20)\n",
      "memory usage: 1.7+ MB\n"
     ]
    }
   ],
   "source": [
    "all_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cyclical versions of begin date features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_data = add_cyclical_features(all_data, 'start_dayofmonth_int', 'start_dayofmonth', 30.44)\n",
    "\n",
    "all_data = add_cyclical_features(all_data, 'start_month_int', 'start_month', 12.00)\n",
    "\n",
    "all_data = add_cyclical_features(all_data, 'start_dayofweek_int', 'start_dayofweek', 7.00)\n",
    "\n",
    "all_data = add_cyclical_features(all_data, 'start_dayofyear_int', 'start_dayofyear', 365.00)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7043 entries, 0 to 7042\n",
      "Data columns (total 40 columns):\n",
      " #   Column                Non-Null Count  Dtype         \n",
      "---  ------                --------------  -----         \n",
      " 0   customer_id           7043 non-null   object        \n",
      " 1   begin_date            7043 non-null   datetime64[ns]\n",
      " 2   end_date              1869 non-null   datetime64[ns]\n",
      " 3   type                  7043 non-null   object        \n",
      " 4   paperless_billing     7043 non-null   object        \n",
      " 5   payment_method        7043 non-null   object        \n",
      " 6   monthly_charges       7043 non-null   float64       \n",
      " 7   total_charges         7032 non-null   float64       \n",
      " 8   gender                7043 non-null   object        \n",
      " 9   senior_citizen        7043 non-null   int64         \n",
      " 10  partner               7043 non-null   object        \n",
      " 11  dependents            7043 non-null   object        \n",
      " 12  p_i_or_b              7043 non-null   object        \n",
      " 13  internet_service      5517 non-null   object        \n",
      " 14  online_security       5517 non-null   object        \n",
      " 15  online_backup         5517 non-null   object        \n",
      " 16  device_protection     5517 non-null   object        \n",
      " 17  tech_support          5517 non-null   object        \n",
      " 18  streaming_tv          5517 non-null   object        \n",
      " 19  streaming_movies      5517 non-null   object        \n",
      " 20  multiple_lines        6361 non-null   object        \n",
      " 21  churn                 7043 non-null   int64         \n",
      " 22  customer_duration     7043 non-null   float64       \n",
      " 23  start_year_int        7043 non-null   int64         \n",
      " 24  start_year_cat        7043 non-null   object        \n",
      " 25  start_month_int       7043 non-null   int64         \n",
      " 26  start_month_cat       7043 non-null   object        \n",
      " 27  start_dayofmonth_int  7043 non-null   int64         \n",
      " 28  start_dayofmonth_cat  7043 non-null   object        \n",
      " 29  start_dayofweek_int   7043 non-null   int64         \n",
      " 30  start_dayofweek_cat   7043 non-null   object        \n",
      " 31  start_dayofyear_int   7043 non-null   int64         \n",
      " 32  start_dayofmonth_sin  7043 non-null   float64       \n",
      " 33  start_dayofmonth_cos  7043 non-null   float64       \n",
      " 34  start_month_sin       7043 non-null   float64       \n",
      " 35  start_month_cos       7043 non-null   float64       \n",
      " 36  start_dayofweek_sin   7043 non-null   float64       \n",
      " 37  start_dayofweek_cos   7043 non-null   float64       \n",
      " 38  start_dayofyear_sin   7043 non-null   float64       \n",
      " 39  start_dayofyear_cos   7043 non-null   float64       \n",
      "dtypes: datetime64[ns](2), float64(11), int64(7), object(20)\n",
      "memory usage: 2.1+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>begin_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>type</th>\n",
       "      <th>paperless_billing</th>\n",
       "      <th>payment_method</th>\n",
       "      <th>monthly_charges</th>\n",
       "      <th>total_charges</th>\n",
       "      <th>gender</th>\n",
       "      <th>senior_citizen</th>\n",
       "      <th>...</th>\n",
       "      <th>start_dayofweek_cat</th>\n",
       "      <th>start_dayofyear_int</th>\n",
       "      <th>start_dayofmonth_sin</th>\n",
       "      <th>start_dayofmonth_cos</th>\n",
       "      <th>start_month_sin</th>\n",
       "      <th>start_month_cos</th>\n",
       "      <th>start_dayofweek_sin</th>\n",
       "      <th>start_dayofweek_cos</th>\n",
       "      <th>start_dayofyear_sin</th>\n",
       "      <th>start_dayofyear_cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0002-orfbo</td>\n",
       "      <td>2019-05-01</td>\n",
       "      <td>NaT</td>\n",
       "      <td>one year</td>\n",
       "      <td>yes</td>\n",
       "      <td>mailed check</td>\n",
       "      <td>65.6</td>\n",
       "      <td>593.30</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>121</td>\n",
       "      <td>0.20495</td>\n",
       "      <td>0.978773</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "      <td>4.338837e-01</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>0.871706</td>\n",
       "      <td>-0.490029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0003-mknfe</td>\n",
       "      <td>2019-05-01</td>\n",
       "      <td>NaT</td>\n",
       "      <td>month-to-month</td>\n",
       "      <td>no</td>\n",
       "      <td>mailed check</td>\n",
       "      <td>59.9</td>\n",
       "      <td>542.40</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>121</td>\n",
       "      <td>0.20495</td>\n",
       "      <td>0.978773</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "      <td>4.338837e-01</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>0.871706</td>\n",
       "      <td>-0.490029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0004-tlhlj</td>\n",
       "      <td>2019-09-01</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>month-to-month</td>\n",
       "      <td>yes</td>\n",
       "      <td>electronic check</td>\n",
       "      <td>73.9</td>\n",
       "      <td>280.85</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>244</td>\n",
       "      <td>0.20495</td>\n",
       "      <td>0.978773</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-1.836970e-16</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.871706</td>\n",
       "      <td>-0.490029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0011-igkff</td>\n",
       "      <td>2018-12-01</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>month-to-month</td>\n",
       "      <td>yes</td>\n",
       "      <td>electronic check</td>\n",
       "      <td>98.0</td>\n",
       "      <td>1237.85</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>335</td>\n",
       "      <td>0.20495</td>\n",
       "      <td>0.978773</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>-7.818315e-01</td>\n",
       "      <td>0.623490</td>\n",
       "      <td>-0.493776</td>\n",
       "      <td>0.869589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0013-exchz</td>\n",
       "      <td>2019-09-01</td>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>month-to-month</td>\n",
       "      <td>yes</td>\n",
       "      <td>mailed check</td>\n",
       "      <td>83.9</td>\n",
       "      <td>267.40</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>244</td>\n",
       "      <td>0.20495</td>\n",
       "      <td>0.978773</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-1.836970e-16</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.871706</td>\n",
       "      <td>-0.490029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  customer_id begin_date   end_date            type paperless_billing  \\\n",
       "0  0002-orfbo 2019-05-01        NaT        one year               yes   \n",
       "1  0003-mknfe 2019-05-01        NaT  month-to-month                no   \n",
       "2  0004-tlhlj 2019-09-01 2020-01-01  month-to-month               yes   \n",
       "3  0011-igkff 2018-12-01 2020-01-01  month-to-month               yes   \n",
       "4  0013-exchz 2019-09-01 2019-12-01  month-to-month               yes   \n",
       "\n",
       "     payment_method  monthly_charges  total_charges  gender  senior_citizen  \\\n",
       "0      mailed check             65.6         593.30  female               0   \n",
       "1      mailed check             59.9         542.40    male               0   \n",
       "2  electronic check             73.9         280.85    male               0   \n",
       "3  electronic check             98.0        1237.85    male               1   \n",
       "4      mailed check             83.9         267.40  female               1   \n",
       "\n",
       "   ... start_dayofweek_cat start_dayofyear_int start_dayofmonth_sin  \\\n",
       "0  ...                   2                 121              0.20495   \n",
       "1  ...                   2                 121              0.20495   \n",
       "2  ...                   6                 244              0.20495   \n",
       "3  ...                   5                 335              0.20495   \n",
       "4  ...                   6                 244              0.20495   \n",
       "\n",
       "  start_dayofmonth_cos start_month_sin start_month_cos start_dayofweek_sin  \\\n",
       "0             0.978773    5.000000e-01   -8.660254e-01        4.338837e-01   \n",
       "1             0.978773    5.000000e-01   -8.660254e-01        4.338837e-01   \n",
       "2             0.978773   -1.000000e+00   -1.836970e-16       -2.449294e-16   \n",
       "3             0.978773   -2.449294e-16    1.000000e+00       -7.818315e-01   \n",
       "4             0.978773   -1.000000e+00   -1.836970e-16       -2.449294e-16   \n",
       "\n",
       "  start_dayofweek_cos start_dayofyear_sin start_dayofyear_cos  \n",
       "0           -0.900969            0.871706           -0.490029  \n",
       "1           -0.900969            0.871706           -0.490029  \n",
       "2            1.000000           -0.871706           -0.490029  \n",
       "3            0.623490           -0.493776            0.869589  \n",
       "4            1.000000           -0.871706           -0.490029  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(all_data.info())\n",
    "all_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this is the final version of this project, we have already tried different combinations of features during cross validation, and have utilized SHAP analyses to help discern which combinations of features lead to data leakage. As it turns out, including any day_of_week variables in conjunction with customer_duration allows the model to deterimine with near certainty whether or not the customer has churned. This is likely the result of a process of elimination about when the customer must have started given the day of week they started. Since each customer started on the first, there are only a limited number of day_of_week values a customer could have and still have a customer_duation value for as long as they did. Insofar as the model can tell based on the combination of the inferred start date and the customer_duration value that the customer is not still a customer, the model knows the customer has churned, and we have a serious case of data leakage on our hands. \n",
    "\n",
    "For all of the above reasons, we are dropping any and all start_date variables from our data set. The below code drops columns that were never intended to be features in the first place (mostly temporary features to help engineer other features), and then it drops the date columns separately for clarity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop cols that are not features\n",
    "features = all_data.drop(columns=['customer_id', \n",
    "                                  'begin_date', \n",
    "                                  'end_date',\n",
    "                                  'churn',\n",
    "                                  'start_month_int',\n",
    "                                  'start_dayofmonth_int',\n",
    "                                  'start_dayofweek_int',\n",
    "                                  'start_dayofyear_int'])\n",
    "\n",
    "# Drop columns that lead to data leakage when paired with customer_duration\n",
    "cols_to_drop = ['start_year_int',\n",
    "                'start_year_cat',\n",
    "                'start_month_cat',\n",
    "                'start_dayofmonth_cat',\n",
    "                'start_dayofweek_cat',\n",
    "                'start_dayofmonth_sin',\n",
    "                'start_dayofmonth_cos',\n",
    "                'start_month_sin',\n",
    "                'start_month_cos',\n",
    "                'start_dayofyear_sin',\n",
    "                'start_dayofyear_cos',\n",
    "                'start_dayofweek_sin',\n",
    "                'start_dayofweek_cos']\n",
    "\n",
    "features = features.drop(columns=cols_to_drop)\n",
    "\n",
    "target = all_data['churn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>paperless_billing</th>\n",
       "      <th>payment_method</th>\n",
       "      <th>monthly_charges</th>\n",
       "      <th>total_charges</th>\n",
       "      <th>gender</th>\n",
       "      <th>senior_citizen</th>\n",
       "      <th>partner</th>\n",
       "      <th>dependents</th>\n",
       "      <th>p_i_or_b</th>\n",
       "      <th>internet_service</th>\n",
       "      <th>online_security</th>\n",
       "      <th>online_backup</th>\n",
       "      <th>device_protection</th>\n",
       "      <th>tech_support</th>\n",
       "      <th>streaming_tv</th>\n",
       "      <th>streaming_movies</th>\n",
       "      <th>multiple_lines</th>\n",
       "      <th>customer_duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one year</td>\n",
       "      <td>yes</td>\n",
       "      <td>mailed check</td>\n",
       "      <td>65.6</td>\n",
       "      <td>593.30</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>both</td>\n",
       "      <td>dsl</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>261.086707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>month-to-month</td>\n",
       "      <td>no</td>\n",
       "      <td>mailed check</td>\n",
       "      <td>59.9</td>\n",
       "      <td>542.40</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>both</td>\n",
       "      <td>dsl</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>261.113430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>month-to-month</td>\n",
       "      <td>yes</td>\n",
       "      <td>electronic check</td>\n",
       "      <td>73.9</td>\n",
       "      <td>280.85</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>both</td>\n",
       "      <td>fiber optic</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>108.220991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>month-to-month</td>\n",
       "      <td>yes</td>\n",
       "      <td>electronic check</td>\n",
       "      <td>98.0</td>\n",
       "      <td>1237.85</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>both</td>\n",
       "      <td>fiber optic</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>382.821665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>month-to-month</td>\n",
       "      <td>yes</td>\n",
       "      <td>mailed check</td>\n",
       "      <td>83.9</td>\n",
       "      <td>267.40</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>both</td>\n",
       "      <td>fiber optic</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>76.251027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             type paperless_billing    payment_method  monthly_charges  \\\n",
       "0        one year               yes      mailed check             65.6   \n",
       "1  month-to-month                no      mailed check             59.9   \n",
       "2  month-to-month               yes  electronic check             73.9   \n",
       "3  month-to-month               yes  electronic check             98.0   \n",
       "4  month-to-month               yes      mailed check             83.9   \n",
       "\n",
       "   total_charges  gender  senior_citizen partner dependents p_i_or_b  \\\n",
       "0         593.30  female               0     yes        yes     both   \n",
       "1         542.40    male               0      no         no     both   \n",
       "2         280.85    male               0      no         no     both   \n",
       "3        1237.85    male               1     yes         no     both   \n",
       "4         267.40  female               1     yes         no     both   \n",
       "\n",
       "  internet_service online_security online_backup device_protection  \\\n",
       "0              dsl              no           yes                no   \n",
       "1              dsl              no            no                no   \n",
       "2      fiber optic              no            no               yes   \n",
       "3      fiber optic              no           yes               yes   \n",
       "4      fiber optic              no            no                no   \n",
       "\n",
       "  tech_support streaming_tv streaming_movies multiple_lines  customer_duration  \n",
       "0          yes          yes               no             no         261.086707  \n",
       "1           no           no              yes            yes         261.113430  \n",
       "2           no           no               no             no         108.220991  \n",
       "3           no          yes              yes             no         382.821665  \n",
       "4          yes          yes               no             no          76.251027  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's convert all categorical variables to dtype cat for native handling in gradient boosting algorithms, and get our final training and testing sets with train_test_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of categorical cols\n",
    "categorical_cols = ['type',\n",
    "                    'total_charges',\n",
    "                    'paperless_billing',\n",
    "                    'payment_method',\n",
    "                    'gender', \n",
    "                    'partner',\n",
    "                    'dependents',\n",
    "                    'p_i_or_b',\n",
    "                    'internet_service',\n",
    "                    'online_security',\n",
    "                    'online_backup',\n",
    "                    'device_protection',\n",
    "                    'tech_support',\n",
    "                    'streaming_tv',\n",
    "                    'streaming_movies',\n",
    "                    'multiple_lines']\n",
    "\n",
    "features[categorical_cols] = features[categorical_cols].astype('category')\n",
    "\n",
    "features_train, features_test, target_train, target_test = train_test_split(features, target, stratify=target, test_size=0.2, random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>paperless_billing</th>\n",
       "      <th>payment_method</th>\n",
       "      <th>monthly_charges</th>\n",
       "      <th>total_charges</th>\n",
       "      <th>gender</th>\n",
       "      <th>senior_citizen</th>\n",
       "      <th>partner</th>\n",
       "      <th>dependents</th>\n",
       "      <th>p_i_or_b</th>\n",
       "      <th>internet_service</th>\n",
       "      <th>online_security</th>\n",
       "      <th>online_backup</th>\n",
       "      <th>device_protection</th>\n",
       "      <th>tech_support</th>\n",
       "      <th>streaming_tv</th>\n",
       "      <th>streaming_movies</th>\n",
       "      <th>multiple_lines</th>\n",
       "      <th>customer_duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1227</th>\n",
       "      <td>month-to-month</td>\n",
       "      <td>no</td>\n",
       "      <td>mailed check</td>\n",
       "      <td>29.15</td>\n",
       "      <td>29.15</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>internet</td>\n",
       "      <td>dsl</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.283308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3585</th>\n",
       "      <td>month-to-month</td>\n",
       "      <td>yes</td>\n",
       "      <td>electronic check</td>\n",
       "      <td>45.30</td>\n",
       "      <td>45.30</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>both</td>\n",
       "      <td>dsl</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>16.766160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3920</th>\n",
       "      <td>month-to-month</td>\n",
       "      <td>yes</td>\n",
       "      <td>electronic check</td>\n",
       "      <td>94.20</td>\n",
       "      <td>1046.10</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>both</td>\n",
       "      <td>fiber optic</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>351.398079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>two year</td>\n",
       "      <td>yes</td>\n",
       "      <td>mailed check</td>\n",
       "      <td>29.60</td>\n",
       "      <td>299.05</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>internet</td>\n",
       "      <td>dsl</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>293.301260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6829</th>\n",
       "      <td>month-to-month</td>\n",
       "      <td>no</td>\n",
       "      <td>mailed check</td>\n",
       "      <td>20.00</td>\n",
       "      <td>32.70</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>phone</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>48.921917</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                type paperless_billing    payment_method  monthly_charges  \\\n",
       "1227  month-to-month                no      mailed check            29.15   \n",
       "3585  month-to-month               yes  electronic check            45.30   \n",
       "3920  month-to-month               yes  electronic check            94.20   \n",
       "423         two year               yes      mailed check            29.60   \n",
       "6829  month-to-month                no      mailed check            20.00   \n",
       "\n",
       "     total_charges  gender  senior_citizen partner dependents  p_i_or_b  \\\n",
       "1227         29.15    male               0      no         no  internet   \n",
       "3585         45.30  female               0      no         no      both   \n",
       "3920       1046.10  female               0      no         no      both   \n",
       "423         299.05  female               0      no         no  internet   \n",
       "6829         32.70    male               0      no         no     phone   \n",
       "\n",
       "     internet_service online_security online_backup device_protection  \\\n",
       "1227              dsl              no            no                no   \n",
       "3585              dsl              no            no                no   \n",
       "3920      fiber optic              no            no                no   \n",
       "423               dsl              no            no                no   \n",
       "6829              NaN             NaN           NaN               NaN   \n",
       "\n",
       "     tech_support streaming_tv streaming_movies multiple_lines  \\\n",
       "1227          yes           no               no            NaN   \n",
       "3585           no           no               no             no   \n",
       "3920           no          yes              yes            yes   \n",
       "423           yes           no               no            NaN   \n",
       "6829          NaN          NaN              NaN             no   \n",
       "\n",
       "      customer_duration  \n",
       "1227          16.283308  \n",
       "3585          16.766160  \n",
       "3920         351.398079  \n",
       "423          293.301260  \n",
       "6829          48.921917  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1227    0\n",
       "3585    1\n",
       "3920    1\n",
       "423     0\n",
       "6829    0\n",
       "Name: churn, dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's save the relevant data sets to .parquet files to maintain dtype integrity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save training and test features \n",
    "features_train.to_parquet('features_train.parquet', index=False)\n",
    "features_test.to_parquet('features_test.parquet', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save training target and test target\n",
    "target_train.to_frame().to_parquet('target_train.parquet', index=False)\n",
    "target_test.to_frame().to_parquet('target_test.parquet', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for Hyperparameter tuning, Cross Validation and Test Set Performance Evaluation of the Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = \"\"\"\n",
    "from typing import Optional\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, recall_score, roc_curve\n",
    "\n",
    "# Define a function that returns best hyperparameters (roc_auc) during cross validation\n",
    "def tuning_cv(features_train: pd.DataFrame, \n",
    "              target_train: pd.Series, \n",
    "              model: BaseEstimator, \n",
    "              param_grid: dict[str, list], \n",
    "              scoring: str = 'roc_auc',\n",
    "              cv: int = 3,\n",
    "              cat_features: Optional[list[str]] = None) -> BaseEstimator:\n",
    "    \\\"\"\"\n",
    "    Returns the model with the hyperparameters that performed the best, prints the hyperparameters,\n",
    "    and prints the best accuracy score (default accuracy metric is roc_auc).\n",
    "    \\\"\"\"\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=model,\n",
    "        param_grid=param_grid,\n",
    "        cv=cv,\n",
    "        scoring=scoring,\n",
    "        verbose=1)\n",
    "\n",
    "    if cat_features:\n",
    "        grid_search.fit(features_train, target_train, cat_features=cat_features)\n",
    "    else:\n",
    "        grid_search.fit(features_train, target_train)\n",
    "\n",
    "    print(\"Best parameters found: \", grid_search.best_params_)\n",
    "    print(\"Best cross-validation score: \", grid_search.best_score_)\n",
    "\n",
    "    return grid_search.best_estimator_\n",
    "\n",
    "# Define a function that calculates the accuracy score for the given model \n",
    "def accuracy_calc(features_train: pd.DataFrame, \n",
    "                  target_train: pd.Series, \n",
    "                  returned_estimator: BaseEstimator, \n",
    "                  cv: int = 3, \n",
    "                  scoring: str = 'accuracy') -> None:\n",
    "    \\\"\"\"\n",
    "    Calculates and prints the accuracy score.\n",
    "    \\\"\"\"\n",
    "    scores = cross_val_score(\n",
    "        returned_estimator,\n",
    "        features_train,\n",
    "        target_train,\n",
    "        cv=cv,\n",
    "        scoring=scoring)\n",
    "\n",
    "    print(\"Mean cross validated accuracy of best estimator during cross validation:\", scores.mean())\n",
    "\n",
    "# Define a function that performs a SHAP analysis for the given model\n",
    "def shap_eval(returned_estimator: BaseEstimator, \n",
    "              features: pd.DataFrame, \n",
    "              target: pd.Series) -> None:\n",
    "    \\\"\"\"\n",
    "    Calculates and prints SHAP values for each feature and prints SHAP plot.\n",
    "    \\\"\"\"\n",
    "    returned_estimator.fit(features, target)\n",
    "    explainer = shap.TreeExplainer(returned_estimator)\n",
    "    shap_values = explainer.shap_values(features)\n",
    "\n",
    "    feature_names = list(features.columns)\n",
    "    mean_abs_impacts = np.mean(np.abs(shap_values), axis=0)\n",
    "    for name, val in zip(feature_names, mean_abs_impacts):\n",
    "        print(f\"{name}: {val}\")\n",
    "    shap.summary_plot(shap_values, features)\n",
    "    plt.show()\n",
    "\n",
    "# Define a function to calculate the best decision threshold for the given model \n",
    "def threshold_calc(returned_estimator: BaseEstimator, \n",
    "                   features_train: pd.DataFrame, \n",
    "                   target_train: pd.Series, \n",
    "                   method: str = 'predict_proba', \n",
    "                   cv: int = 5) -> float: \n",
    "    \\\"\"\"\n",
    "    Calculate the optimal threshold for predictions. Utilizes 5 folds during cross validation \n",
    "    instead of 3 as we used during hyperparameter tuning to minimize overfitting as much as \n",
    "    possible. Prints and returns optimal threshold value. \n",
    "    \\\"\"\"\n",
    "    probs = cross_val_predict(\n",
    "        returned_estimator,\n",
    "        features_train,\n",
    "        target_train,\n",
    "        method=method,\n",
    "        cv=cv)[:, 1]\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(target_train, probs)\n",
    "    youden_j = tpr - fpr\n",
    "    optimal_idx = np.argmax(youden_j)\n",
    "    optimal_threshold = thresholds[optimal_idx]\n",
    "    print(f\"Optimal threshold: {optimal_threshold:.4f}\")\n",
    "    return optimal_threshold\n",
    "\n",
    "# Define a function that prints metrics for model performance on test set\n",
    "def print_metrics(returned_estimator: BaseEstimator, \n",
    "                  features_train: pd.DataFrame, \n",
    "                  target_train: pd.Series, \n",
    "                  features_test: pd.DataFrame, \n",
    "                  target_test: pd.Series,\n",
    "                  optimal_threshold: float) -> None:\n",
    "    \\\"\"\"\n",
    "    1. Trains model on full training set\n",
    "    2. Then makes predictions on test set\n",
    "    3. Calculates and prints roc_auc, accuracy, and recall scores for the model's predictions\n",
    "    \\\"\"\"\n",
    "    returned_estimator.fit(features_train, target_train)\n",
    "    pred_prob = returned_estimator.predict_proba(features_test)[:, 1]\n",
    "\n",
    "    roc_auc = roc_auc_score(target_test, pred_prob)\n",
    "    print(f\"Roc_Auc score for model: {roc_auc:.4f}\")\n",
    "\n",
    "    preds = pred_prob > optimal_threshold\n",
    "    accuracy = accuracy_score(target_test, preds)\n",
    "    print(f\"Accuracy score for model: {accuracy:.4f}\")\n",
    "\n",
    "    recall = recall_score(target_test, preds)\n",
    "    print(f\"Recall score for model: {recall:.4f}\")\n",
    "\"\"\"\n",
    "\n",
    "with open(\"src/model_utils.py\", \"w\") as f:\n",
    "    f.write(code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBMClassifier Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare a script for LGBMClassifier Hyperparameter tuning and SHAP analysis \n",
    "# Please note that the SHAP plot may not render in Google Colab when run from this .py script. \n",
    "# If it doesn't, the problem can be solved by entering the code to display the plot manually in a separate Colab notebook cell.\n",
    "# (This code is tailored for Google Colab, but can be revised to run on any desired GPU platform.)\n",
    "\n",
    "# Define a function to clean zero-width characters \n",
    "def clean(text):\n",
    "    return text.replace('\\u200b', '')\n",
    "\n",
    "# ===== Colab Setup (Insert this directly into the script) =====\n",
    "colab_setup = clean(\"\"\"\n",
    "# ============================\n",
    "# COLAB SETUP (Run only if in Colab)\n",
    "# ============================\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "try:\n",
    "    import google.colab\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    # Adjust this path if needed\n",
    "    project_path = Path('/content/drive/MyDrive/predicting_cust_churn')\n",
    "    sys.path.append(str(project_path))\n",
    "    os.chdir(project_path)\n",
    "\n",
    "except ImportError:\n",
    "    pass  # Not running in Colab\n",
    "\"\"\")\n",
    "\n",
    "# Define the import section as a string \n",
    "init_str = clean(\"\"\"\n",
    "\n",
    "# For type hints\n",
    "from typing import Optional\n",
    "\n",
    "# Colab utilities\n",
    "from google.colab import files\n",
    "\n",
    "# Core third-party libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# LightGBM\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# Scikit-learn: model selection and evaluation\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Local Utilities\n",
    "from src.model_utils import tuning_cv, accuracy_calc, shap_eval\n",
    "\"\"\")\n",
    "\n",
    "# Write to a script file\n",
    "with open('src/lightgbm_gpu_tuning.py', 'w') as f:\n",
    "    \n",
    "    # Write the Colab setup first\n",
    "    f.write(colab_setup)\n",
    "    f.write('\\n\\n')\n",
    "\n",
    "    # Then the import section\n",
    "    f.write(init_str)\n",
    "    f.write('\\n\\n')\n",
    "\n",
    "    # Write the main script logic\n",
    "    main_script = clean(\"\"\"\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    features_train = pd.read_parquet('features_train.parquet')\n",
    "    target_train = pd.read_parquet('target_train.parquet').iloc[:, 0]\n",
    "\n",
    "    # We need to make sure we have a version of LGBMClassifier that can run on GPUs\n",
    "    print(\"LightGBM version:\", lgb.__version__)\n",
    "\n",
    "    try:\n",
    "        model_light = lgb.LGBMClassifier(device='gpu', eval_metric='auc', random_state=12345)\n",
    "        print(\"GPU support is enabled for LightGBM.\")\n",
    "    except Exception as e:\n",
    "        print(\"GPU support is NOT enabled:\", e)\n",
    "\n",
    "    param_grid = {\n",
    "        'num_leaves': [15, 31],                 \n",
    "        'max_depth': [5, -1],                   \n",
    "        'learning_rate': [0.01, 0.1],           \n",
    "        'n_estimators': [100, 300],             \n",
    "        'subsample': [0.8, 1.0],                \n",
    "        'colsample_bytree': [0.8, 1.0],         \n",
    "        'class_weight': [None, 'balanced']      \n",
    "    }\n",
    "\n",
    "    model_light = tuning_cv(features_train, \n",
    "                            target_train, \n",
    "                            model_light, \n",
    "                            param_grid)\n",
    "\n",
    "    accuracy_calc(features_train, \n",
    "                  target_train,  \n",
    "                  model_light)\n",
    "\n",
    "    shap_eval(model_light, \n",
    "              features_train, \n",
    "              target_train)\n",
    "\"\"\")\n",
    "\n",
    "    f.write(main_script)\n",
    "    f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CatBoostClassifier Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare a script for CatBoostClassifier Hyperparameter tuning and SHAP analysis\n",
    "# Plese note that the SHAP plot may not plot in google colab when run from this .py script. If it doesn't this problem can be solved by \n",
    "# entering the code to display the plot manually in a separate google colab notebook cell\n",
    "# (This code is tailored for google colab, but can be revised to run on desired GPU platofrm)\n",
    "\n",
    "# Define a function to clean zero-width characters \n",
    "def clean(text):\n",
    "    return text.replace('\\u200b', '')\n",
    "\n",
    "# ===== Colab Setup (Insert this directly into the script) =====\n",
    "colab_setup = clean(\"\"\"\n",
    "# ============================\n",
    "# COLAB SETUP (Run only if in Colab)\n",
    "# ============================\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "try:\n",
    "    import google.colab\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    # Adjust this path if needed\n",
    "    project_path = Path('/content/drive/MyDrive/predicting_cust_churn')\n",
    "    sys.path.append(str(project_path))\n",
    "    os.chdir(project_path)\n",
    "\n",
    "except ImportError:\n",
    "    pass  # Not running in Colab\n",
    "\"\"\")\n",
    "\n",
    "# Define the import section as a string \n",
    "init_str = clean(\"\"\"\n",
    "\n",
    "# For type hints\n",
    "from typing import Optional\n",
    "\n",
    "# Colab utilities\n",
    "from google.colab import files\n",
    "\n",
    "# Core third-party libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# CatBoost\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "\n",
    "# Scikit-learn: model selection and evaluation and type hints\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Local Utilities\n",
    "from src.model_utils import tuning_cv, accuacy_calc, shap_eval\n",
    "\"\"\")\n",
    "\n",
    "# Write to a script file\n",
    "with open('src/catboost_gpu_tuning.py', 'w') as f:\n",
    "    \n",
    "    # Write the import section\n",
    "    f.write(init_str)\n",
    "    f.write('\\n\\n')\n",
    "\n",
    "    # Write the main script logic\n",
    "    main_script = clean(\"\"\"\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    features_train = pd.read_parquet('features_train.parquet')\n",
    "    target_train = pd.read_parquet('target_train.parquet').iloc[:, 0]\n",
    "\n",
    "    cat_cols = features_train.select_dtypes(include='category').columns.tolist()\n",
    "\n",
    "    model_cat = CatBoostClassifier(random_seed=12345, eval_metric='AUC', task_type='GPU')\n",
    "\n",
    "    \n",
    "\n",
    "    param_grid = {\n",
    "    'iterations': [100, 300],               # Keep it light but effective\n",
    "    'depth': [4, 6],                        # Balanced tree depth options\n",
    "    'learning_rate': [0.05, 0.1],           # Two sensible learning rates\n",
    "    'l2_leaf_reg': [3, 7],                  # Light regularization options\n",
    "    'border_count': [32, 50],               # Numerical feature binning splits\n",
    "    'random_strength': [1, 2],              # Control randomness in splitting\n",
    "    'bagging_temperature': [0, 1],          # Simple bagging temps to test\n",
    "    'scale_pos_weight': [1, 3]}             # Basic class imbalance adjustment\n",
    "\n",
    "    model_cat = tuning_cv(features_train, \n",
    "                                   target_train, \n",
    "                                   model_cat, \n",
    "                                   param_grid,\n",
    "                                   cat_features=cat_cols)\n",
    "\n",
    "    accuracy_calc(features_train, \n",
    "                  target_train,  \n",
    "                  model_cat)\n",
    "\n",
    "    \n",
    "\n",
    "    shap_eval(model_cat, \n",
    "              features_train, \n",
    "              target_train)\n",
    "\"\"\")\n",
    "\n",
    "    f.write(main_script)\n",
    "    f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoostClassifier Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare a script for XGBoostClassifier Hyperparameter tuning and SHAP analysis. Plese note that the SHAP plot may not plot in google colab when run from this .py script. If it doesn't this problem can be solved by \n",
    "# entering the code to display the plot manually in a separate google colab notebook cell \n",
    "# (This code was tailored for google colab, but can be revised to run on desired GPU platofrm)\n",
    "\n",
    "# Define a function to clean zero-width characters \n",
    "def clean(text):\n",
    "    return text.replace('\\u200b', '')\n",
    "\n",
    "# ===== Colab Setup (Insert this directly into the script) =====\n",
    "colab_setup = clean(\"\"\"\n",
    "# ============================\n",
    "# COLAB SETUP (Run only if in Colab)\n",
    "# ============================\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "try:\n",
    "    import google.colab\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    # Adjust this path if needed\n",
    "    project_path = Path('/content/drive/MyDrive/predicting_cust_churn')\n",
    "    sys.path.append(str(project_path))\n",
    "    os.chdir(project_path)\n",
    "\n",
    "except ImportError:\n",
    "    pass  # Not running in Colab\n",
    "\"\"\")\n",
    "\n",
    "# Define the import section as a string \n",
    "init_str = clean(\"\"\"\n",
    "\n",
    "# For type hints\n",
    "from typing import Optional\n",
    "\n",
    "# Colab utilities\n",
    "from google.colab import files\n",
    "\n",
    "# Core third-party libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "\n",
    "# XGBoost\n",
    "import xgboost\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Scikit-learn: model selection and evaluation and type hints\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Local Utilities\n",
    "from src.model_utils import tuning_cv, accuracy_calc, shap_eval\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "# Write to a script file\n",
    "with open('src/xgb_gpu_tuning.py', 'w') as f:\n",
    "    \n",
    "    # Write the import section\n",
    "    f.write(init_str)\n",
    "    f.write('\\n\\n')\n",
    "\n",
    "    # Write the main script logic\n",
    "    main_script = clean(\"\"\"\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # Make sure we have xgboost version that can handle categorical variables natively\n",
    "    print(xgboost.__version__)\n",
    "\n",
    "    features_train = pd.read_parquet('features_train.parquet')\n",
    "    target_train = pd.read_parquet('target_train.parquet').iloc[:, 0]\n",
    "    \n",
    "    model_xgb = XGBClassifier(\n",
    "    tree_method=\"gpu_hist\",\n",
    "    enable_categorical=True,        # enables native handling of categorical features\n",
    "    predictor=\"gpu_predictor\",      # optional for faster inference\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='auc',\n",
    "    random_state=12345)\n",
    "\n",
    "    param_grid = {\n",
    "    'n_estimators': [100, 300],\n",
    "    'max_depth': [3, 5],\n",
    "    'learning_rate': [0.05, 0.1],\n",
    "    'subsample': [0.7, 1.0],\n",
    "    'colsample_bytree': [0.7, 1.0],\n",
    "    'scale_pos_weight': [3, 4]}  # imbalance adjustment\n",
    "\n",
    "\n",
    "    model_xgb = tuning_cv(features_train, \n",
    "                                   target_train, \n",
    "                                   model_xgb, \n",
    "                                   param_grid)\n",
    "\n",
    "    accuracy_calc(features_train, \n",
    "                  target_train,  \n",
    "                  model_xgb)\n",
    "\n",
    "    \n",
    "\n",
    "    shap_eval(model_xgb, \n",
    "              features_train, \n",
    "              target_train)\n",
    "\n",
    "    # Save model to project directory\n",
    "    joblib.dump(model_xgb, 'model_xgb.pkl')\n",
    "\"\"\")\n",
    "\n",
    "    f.write(main_script)\n",
    "    f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Threshold Calculation, Final Model Training, Final Model Testing, and Final Model SHAP Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare a script to find the optimal prediction threshold during the cross validation phase,\n",
    "# train the best model on full training set, and measure its performance on test set with roc_auc, accuracy_score, and recall_score\n",
    "# This code will also perform a SHAO analysis on the model's features\n",
    "# Since the model that performed best during hyperparameter tuning was XGBoost that is the model we are giong to use\n",
    "# However, this code can be adjusted slightly to accomodate the other two gradient boosting models we considered as well. \n",
    "# Plese note that the SHAP plot may not plot in google colab when run from this .py script. If it doesn't this problem can be solved by \n",
    "# entering the code to display the plot manually in a separate google colab notebook cell\n",
    "# (This code is tailored for google colab, but can be revised to run on desired GPU platofrm)\n",
    "\n",
    "# Define a function to clean zero-width characters \n",
    "def clean(text):\n",
    "    return text.replace('\\u200b', '')\n",
    "\n",
    "# ===== Colab Setup (Insert this directly into the script) =====\n",
    "colab_setup = clean(\"\"\"\n",
    "# ============================\n",
    "# COLAB SETUP (Run only if in Colab)\n",
    "# ============================\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "try:\n",
    "    import google.colab\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    # Adjust this path if needed\n",
    "    project_path = Path('/content/drive/MyDrive/predicting_cust_churn')\n",
    "    sys.path.append(str(project_path))\n",
    "    os.chdir(project_path)\n",
    "\n",
    "except ImportError:\n",
    "    pass  # Not running in Colab\n",
    "\"\"\")\n",
    "\n",
    "# Define the import section as a string \n",
    "init_str = clean(\"\"\"\n",
    "\n",
    "# Standard library imports\n",
    "import os\n",
    "\n",
    "# For type hints\n",
    "from typing import Optional\n",
    "\n",
    "# Colab utilities\n",
    "from google.colab import files\n",
    "\n",
    "# Core third-party libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "\n",
    "# XGBoost\n",
    "import xgboost\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Scikit-learn: model selection and evaluation and type hints\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "# Local Utilities\n",
    "from src.model_utils import threshold_calc, print_metrics, shap_eval\n",
    "\"\"\")\n",
    "\n",
    "# Write to a script file\n",
    "with open('src/xgb_testing.py', 'w') as f:\n",
    "    \n",
    "    # Write the import section\n",
    "    f.write(init_str)\n",
    "    f.write('\\n\\n')\n",
    "\n",
    "    # Write the main script logic\n",
    "    main_script = clean(\"\"\"\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # Make sure we have xgboost version that can handle categorical variables natively\n",
    "    print(xgboost.__version__)\n",
    "\n",
    "    features_train = pd.read_parquet('features_train.parquet')\n",
    "    target_train = pd.read_parquet('target_train.parquet').iloc[:,0]\n",
    "    \n",
    "    features_test = pd.read_parquet('features_test.parquet')\n",
    "    target_test = pd.read_parquet('target_test.parquet')\n",
    "\n",
    "\n",
    "    # Load model if the file exists\n",
    "    model_path = \"model_xgb.pkl\"\n",
    "    if os.path.exists(model_path):\n",
    "        model_xgb = joblib.load(model_path)\n",
    "        print(\"Loaded model_xgb from file.\")\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"{model_path} not found. Make sure the model was trained and saved.\")\n",
    "\n",
    "\n",
    "    optimal_threshold = threshold_calc(model_xgb, \n",
    "                                    features_train, \n",
    "                                    target_train)\n",
    "\n",
    "    print_metrics(model_xgb, \n",
    "                  features_train, \n",
    "                  target_train, \n",
    "                  features_test, \n",
    "                  target_test,\n",
    "                  optimal_threshold)\n",
    "\n",
    "    shap_eval(model_xgb, \n",
    "              features_test, \n",
    "              target_test)\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "    f.write(main_script)\n",
    "    f.write('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (sprint_17_env)",
   "language": "python",
   "name": "sprint_17_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
